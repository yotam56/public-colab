{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyngrok transformers==4.40.0 sentencepiece==0.1.99 colorlog==6.8.2 uvicorn==0.29.0 pydantic==2.9.2 torch==2.1.2 flash-attn fastapi==0.111.0 torchvision==0.16.2 accelerate==0.27.2 bitsandbytes Pillow==10.1.0 nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from colorlog import ColoredFormatter\n",
    "\n",
    "\n",
    "class SingletonMeta(type):\n",
    "    \"\"\"A metaclass for the Singleton pattern.\"\"\"\n",
    "\n",
    "    _instances = {}\n",
    "\n",
    "    def __call__(cls, *args, **kwargs):\n",
    "        if cls not in cls._instances:\n",
    "            cls._instances[cls] = super().__call__(*args, **kwargs)\n",
    "        return cls._instances[cls]\n",
    "\n",
    "\n",
    "class Logger(metaclass=SingletonMeta):\n",
    "    def __init__(self, level=logging.INFO):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(level)\n",
    "\n",
    "        handler = logging.StreamHandler()\n",
    "\n",
    "        # Color formatting\n",
    "        log_colors = {\n",
    "            \"DEBUG\": \"cyan\",\n",
    "            \"INFO\": \"green\",\n",
    "            \"WARNING\": \"yellow\",\n",
    "            \"ERROR\": \"red\",\n",
    "            \"CRITICAL\": \"red,bg_white\",\n",
    "            \"TIMER\": \"blue\",\n",
    "        }\n",
    "\n",
    "        formatter = ColoredFormatter(\n",
    "            \"%(log_color)s%(levelname)-8s%(reset)s \\033[37m%(message)s\\033[0m \\033[37m[%(module)s/%(funcName)s/line %(lineno)d]\\033[0m\",\n",
    "            datefmt=None,\n",
    "            reset=True,\n",
    "            log_colors=log_colors,\n",
    "        )\n",
    "\n",
    "        handler.setFormatter(formatter)\n",
    "        self.logger.addHandler(handler)\n",
    "        logging.addLevelName(25, \"TIMER\")\n",
    "        self.logger.timer = self.timer\n",
    "\n",
    "    def get_logger(self):\n",
    "        return self.logger\n",
    "\n",
    "    def timer(self, message, *args, **kwargs):\n",
    "        if self.logger.isEnabledFor(logging.DEBUG):\n",
    "            self.logger._log(25, message, args, **kwargs)\n",
    "\n",
    "logger_level = os.getenv(\"LOGGER_LEVEL\", \"INFO\").upper()\n",
    "log_level = getattr(logging, logger_level, logging.INFO)\n",
    "logger = Logger(log_level).get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8055b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def decode_base64_to_image(image_base64: str) -> Image.Image:\n",
    "    try:\n",
    "        image_data = base64.b64decode(image_base64)\n",
    "        image = Image.open(BytesIO(image_data)).convert(\"RGB\")\n",
    "        logger.info(\"Image decoded successfully\")\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error decoding base64 image: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngrok config add-authtoken <missing token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a126516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class MiniCPM_V_2_6_Int4:\n",
    "    def load(self):\n",
    "        self.model_name = \"openbmb/MiniCPM-V-2_6-int4\"\n",
    "        try:\n",
    "            self.model = AutoModel.from_pretrained(\n",
    "                self.model_name, trust_remote_code=True\n",
    "            )\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                self.model_name, trust_remote_code=True\n",
    "            )\n",
    "            self.model.eval()\n",
    "            logger.info(f\"Model {self.model_name} loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load model {self.model_name}: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def infer(self, base64_image: str, question: str):\n",
    "        try:\n",
    "            image = decode_base64_to_image(base64_image)\n",
    "            msgs = [{\"role\": \"user\", \"content\": [image, question]}]\n",
    "            result = self.model.chat(image=None, msgs=msgs, tokenizer=self.tokenizer)\n",
    "            logger.info(\"Inference completed successfully.\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Inference failed: {str(e)}\")\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720aaf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "import uvicorn\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "model_instance = MiniCPM_V_2_6_Int4()\n",
    "model_instance.load()\n",
    "\n",
    "\n",
    "class MultimodalRequest(BaseModel):\n",
    "    question: str\n",
    "    base64_image: str\n",
    "\n",
    "\n",
    "class MultimodalResponse(BaseModel):\n",
    "    prediction: str\n",
    "\n",
    "\n",
    "@app.get(\"/health_check\")\n",
    "async def health_check():\n",
    "    logger.info(\"Health check called.\")\n",
    "    return {\"status\": \"Healthy\"}\n",
    "\n",
    "\n",
    "@app.post(\"/infer\")\n",
    "async def infer(infer_request: MultimodalRequest):\n",
    "    try:\n",
    "        logger.info(\"Received inference request.\")\n",
    "        prediction = model_instance.infer(\n",
    "            infer_request.base64_image, infer_request.question\n",
    "        )\n",
    "        logger.info(\"Returning inference result.\")\n",
    "        return MultimodalResponse(prediction=prediction)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during inference request: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "\n",
    "# Connect to ngrok on Colab\n",
    "ngrok_tunnel = ngrok.connect(\"9200\")\n",
    "print(\"Public URL:\", ngrok_tunnel.public_url)\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Function to forward requests from Colab to your local server\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Starting the Uvicorn server...\")\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=9200)\n",
    "    logger.info(\"Server has started.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
